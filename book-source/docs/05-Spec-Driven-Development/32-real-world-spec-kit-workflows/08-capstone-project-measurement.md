---
title: "Capstone Project: Decomposition Thinking in Action"
chapter: 32
lesson: 8
duration_minutes: 240

# HIDDEN SKILLS METADATA (Institutional Integration Layer)
# Not visible to students; enables competency assessment and differentiation
skills:
  - name: "End-to-End Project Delivery"
    proficiency_level: "B1"
    category: "Technical"
    bloom_level: "Create"
    digcomp_area: "Problem-Solving"
    measurable_at_this_level: "Student can execute complete SpecKit Plus workflow from decomposition through implementation, measurement, and documentation"

  - name: "Metrics & Reflection"
    proficiency_level: "B1"
    category: "Conceptual"
    bloom_level: "Evaluate"
    digcomp_area: "Problem-Solving"
    measurable_at_this_level: "Student can articulate concrete value of decomposition thinking through time-based metrics and can compare sequential vs parallel productivity gains"

  - name: "Portfolio Narrative"
    proficiency_level: "B1"
    category: "Communication"
    bloom_level: "Communicate"
    digcomp_area: "Communication"
    measurable_at_this_level: "Student can explain their project to non-technical stakeholders, emphasizing strategic thinking and transferable skills over tool proficiency"

  - name: "Decomposition Thinking: Mastery"
    proficiency_level: "B2"
    category: "Conceptual"
    bloom_level: "Evaluate"
    digcomp_area: "Problem-Solving"
    measurable_at_this_level: "Student demonstrates comprehensive understanding of decomposition patterns, scaling from 3 to 10-15 agents, and can transfer thinking to human team coordination"

learning_objectives:
  - objective: "Complete a 3-5 feature system using parallel SpecKit Plus workflow"
    proficiency_level: "B1"
    bloom_level: "Create"
    assessment_method: "Working GitHub repository with multi-worktree history and clean integration"

  - objective: "Measure productivity gains and document time tracking worksheet"
    proficiency_level: "B1"
    bloom_level: "Evaluate"
    assessment_method: "Time tracking worksheet showing sequential vs parallel actual measurements"

  - objective: "Create portfolio narrative explaining decomposition thinking to employers"
    proficiency_level: "B1"
    bloom_level: "Communicate"
    assessment_method: "Written reflection essay and 2-minute explanation demonstrating transferability"

  - objective: "Demonstrate mastery by articulating what decomposition teaches about team coordination at scale"
    proficiency_level: "B2"
    bloom_level: "Evaluate"
    assessment_method: "Capstone reflection addressing how learning applies to 10-15 agent coordination"

cognitive_load:
  new_concepts: 10
  assessment: "10 new concepts (decomposition strategy, integration quality, measurement, portfolio narrative, reflection, transferability, scaling, documentation, rubric, celebration) within B2 limit of 10 ✓"

differentiation:
  extension_for_advanced: "Build 5-7 feature system instead of 3; apply Lesson 7 SpecKit orchestration patterns; analyze what decomposition patterns scale to 15 agents"
  remedial_for_struggling: "Focus on 3-feature system with provided starter template; use time tracking to show 2-3x speedup (not 10x); emphasize learning over perfect execution"

# Generation metadata
generated_by: "lesson-writer v3.0.0"
source_spec: "specs/002-chapter-32-redesign/spec.md"
created: "2025-11-06"
last_modified: "2025-11-06"
git_author: "Claude Code"
workflow: "/sp.implement"
version: "1.0.0"
---

# Capstone Project: Decomposition Thinking in Action

## Congratulations!

You've reached the capstone lesson of Chapter 32. Over the past seven lessons, you've learned the core pattern that enables 1 person to coordinate 10-15 autonomous agents (whether AI or human teams): **decomposition thinking**.

You've practiced breaking complex problems into parallelizable units. You've experienced the concrete reality: good decomposition eliminates coordination overhead. You've seen how a 3-5 feature system built sequentially takes 2-3 hours, but built in parallel takes 45 minutes — a **2.5-3x speedup** with no quality sacrifice.

Now comes the final proof: a capstone project where you build something real, measure your productivity gains, and create a portfolio artifact that demonstrates to employers that you can orchestrate 10-15 agents to deliver multi-feature systems faster, cheaper, and with fewer errors.

**The stakes**: This isn't just a learning exercise. This is proof of transformation. After completing this capstone, you can legitimately claim: **"I am a creative orchestrator. I can decompose complex systems, coordinate autonomous teams, and deliver at 10x productivity."**

---

## Section 1: Project Design (30 minutes)

Before you write a single line of code, you need to decide what you're building and whether it's actually decomposable.

### Choosing Your Capstone System

You have three capstone project starters to choose from. Each has been designed to be **genuinely parallelizable** — meaning you can build 3 features simultaneously with minimal merge conflicts.

#### Starter 1: Task Management App

**What you're building**: A web application for managing personal tasks with priorities and sharing.

**Features**:
- **Feature 001-task-crud**: Create, read, update, delete tasks (core data model)
- **Feature 002-priorities**: Add priority levels, filtering by priority, sorting by deadline
- **Feature 003-sharing**: Share tasks with other users, permissions management

**Integration Contracts**:
- Feature 002 depends on Feature 001 (needs task data model from Feature 001)
- Feature 003 depends on Feature 001 (needs task IDs for sharing references)
- Features 002 and 003 are **independent** of each other (can be built simultaneously)

**Stack** (your choice):
- Backend: Python FastAPI, Node.js Express, or Go
- Frontend: React, Vue.js, or Svelte
- Database: SQLite, PostgreSQL, or MongoDB

**Expected Implementation Time**: 2-3 hours total (60 min sequential per feature × 3, but 60-90 min parallel because all 3 run simultaneously)

**Why This Works**: The core data model (Feature 001) is built first in one session. While Feature 001 is finishing, you're already building priorities (Feature 002) and sharing (Feature 003) in parallel sessions. They all depend on the same user schema, so the integration contract is clear and minimal.

---

#### Starter 2: Blog Platform

**What you're building**: A blogging platform with posts, comments, and AI-powered recommendations.

**Features**:
- **Feature 001-posts**: Create, edit, delete blog posts with markdown support
- **Feature 002-comments**: Comment on posts, nested replies, comment moderation
- **Feature 003-recommendations**: AI-powered post recommendations based on reading history

**Integration Contracts**:
- Feature 002 depends on Feature 001 (needs post IDs to attach comments)
- Feature 003 depends on Features 001 AND 002 (needs reading history from comments to train recommendations)
- Features 001 and 002 can start in parallel, Feature 003 waits for both

**Stack Options**:
- Backend: Python Django, Node.js NestJS, or Rust Actix
- Frontend: React with TypeScript, Next.js, or Remix
- Database: PostgreSQL recommended (for relational data)

**Expected Implementation Time**: 2-3 hours total

**Why This Works**: Unlike Task Management (where all 3 features are truly independent), Blog Platform shows **tiered dependencies**. Feature 001 must ship first, then Features 002 and 003 depend on it but are independent of each other. This teaches you what decomposition looks like with realistic dependencies, not artificial independence.

---

#### Starter 3: API Wrapper Service

**What you're building**: A wrapper service around a public API (e.g., GitHub, Stripe, OpenWeather) that adds caching, rate limiting, and authentication.

**Features**:
- **Feature 001-auth**: Implement API key authentication and user account management
- **Feature 002-rate-limiting**: Track API usage, enforce rate limits per user, return 429 responses
- **Feature 003-caching**: Cache API responses, invalidate cache intelligently, reduce upstream calls

**Integration Contracts**:
- Feature 002 depends on Feature 001 (needs user accounts to track usage)
- Feature 003 is independent (caches any endpoint, regardless of auth or rate limiting)
- Features 002 and 003 can be built in parallel and will integrate cleanly

**Stack Options**:
- Backend: Python FastAPI, Node.js Express, or Go
- Cache: Redis or in-memory (SQLite for simplicity)
- Testing: Use a public API (GitHub's REST API is free and well-documented)

**Expected Implementation Time**: 1.5-2.5 hours total

**Why This Works**: This demonstrates cross-cutting concerns (auth applies to everything, caching is orthogonal). It's more technical than the other starters and shows you how decomposition handles infrastructure concerns, not just domain features.

---

### Your Design Exercise (15 minutes)

**Step 1: Choose a Starter**

Pick the starter that excites you most. This matters — you'll be spending 2-3 hours building this system.

- Task Management App: Best if you want clear domain modeling, familiar concepts
- Blog Platform: Best if you want to see realistic dependencies, more complex integration
- API Wrapper: Best if you want to understand infrastructure patterns and cross-cutting concerns

**Step 2: Map Feature Dependencies**

Draw a dependency diagram for your three features:

```
Starter 1 (Task Management):
     Feature 001 (CRUD)
         ↙            ↘
   Feature 002     Feature 003
  (Priorities)    (Sharing)
  [can build simultaneously]

Starter 2 (Blog Platform):
     Feature 001 (Posts)
         ↙            ↘
  Feature 002      Feature 003
  (Comments) [waits for 001 + 002]
             (Recommendations)

Starter 3 (API Wrapper):
     Feature 001 (Auth)
         ↙     ↘
   Feature 002   Feature 003
  (Rate Limit) [independent]
     (Caching)
```

**Step 3: Verify Parallelizability**

Answer these three questions for your system:

1. **Can Feature 001 be built independently?** (Answer should be YES — it's the foundation)
2. **Can Features 002 and 003 be built simultaneously, even if one depends on Feature 001?** (Should be YES for your starter — they wait on Feature 001 to merge, but can be built in parallel)
3. **Are integration contracts clear?** (Can you define which data structures each feature needs from Feature 001?)

If all three answers are YES, you have a parallelizable system. Proceed to execution.

---

## Section 2: Execution — Full Parallel Workflow (150 minutes)

Now you'll execute the complete SpecKit Plus workflow you've learned across Lessons 1-8. You can use the manual approach from Lessons 1-5, or apply the contract-based coordination patterns from Lessons 6-7 for larger systems.

This section describes the **manual approach** (Lessons 1-5). If you're applying contract-based orchestration (Lessons 6-7), adapt these steps accordingly.

### Phase 1: Decomposition & Specification (30 minutes)

**Step 1: Set Up Git Worktrees**

```bash
# In your project root
git worktree list  # See existing worktrees
git worktree add ../feature-001-[name] main
git worktree add ../feature-002-[name] main
git worktree add ../feature-003-[name] main

# Verify all three are set up
git worktree list
```

**Step 2: Write Feature Specifications (In Parallel)**

Open three terminal sessions, one in each worktree. In each session, run:

```bash
# In worktree feature-001
/sp.specify

# In worktree feature-002
/sp.specify

# In worktree feature-003
/sp.specify
```

**Key principle**: All three sessions can run simultaneously. You're not waiting for Feature 001 spec to finish before starting Feature 002 spec — they're all happening in parallel.

**What to include in each spec**:
- User stories explaining the feature's purpose
- Success criteria (how will you know it works?)
- Integration contract: What data does this feature need? What does it provide to others?
- Example: Feature 002 (Priorities) spec should say "Requires: Task model from Feature 001. Provides: Priority filter API"

**Time estimate**: 15-20 minutes total (not 30-60 minutes sequential)

**What you should observe**: Feature numbering auto-increments (001, 002, 003) without conflicts. All three specs reference your shared constitution, ensuring consistency.

---

### Phase 2: Parallel Planning & Tasks (30 minutes)

**In each worktree, run**:

```bash
# In worktree feature-001
/sp.plan
/sp.tasks

# In worktree feature-002
/sp.plan
/sp.tasks

# In worktree feature-003
/sp.plan
/sp.tasks
```

Again, **all three run in parallel**. Total time: ~30 minutes (not 90 minutes sequential).

**What to observe**:
- Plan complexity: Are all three plans roughly similar size? Or is one plan much larger?
- If one plan is significantly larger/complex, it may indicate poor decomposition — you've hidden complexity in one feature
- Tasks: Are the task counts similar across features?

**Reflection**: Take 5 minutes and write in your journal:
- "Feature 001's plan has [X] lessons, Feature 002 has [Y], Feature 003 has [Z]. This tells me decomposition quality is [good/needs improvement] because..."

---

### Phase 3: Parallel Implementation (90 minutes)

**In each worktree, run**:

```bash
# In worktree feature-001
/sp.implement

# In worktree feature-002
/sp.implement

# In worktree feature-003
/sp.implement
```

**Critical insight**: All three implementations are happening **simultaneously**. You're not waiting for one to finish before starting the next.

**How to monitor progress**:
- Use tmux split panes, iTerm2 side-by-side, or separate terminal windows
- Check progress periodically (every 10-15 minutes)
- If one implementation fails, debug while others continue

**Parallel vs Sequential Reality Check**:

If each feature takes ~60 minutes to implement sequentially:
- **Sequential approach**: Feature 001 (60 min) → Feature 002 (60 min) → Feature 003 (60 min) = **180 minutes total**
- **Parallel approach**: All 3 running simultaneously = **60 minutes total** (the longest single feature determines total time)

That's a **3x speedup** with zero quality sacrifice.

**What to watch for**:
- Merge conflicts during integration indicate decomposition problems
- Clean integration (0-1 conflicts) indicates excellent decomposition
- Test failures during integration indicate hidden dependencies

---

### Phase 4: Integration Testing (30 minutes)

Once implementations complete, merge branches in dependency order:

**Step 1: Merge Feature 001**

```bash
git checkout main
git merge feature-001-[name]
# Run tests, verify Feature 001 works standalone
```

**Step 2: Merge Feature 002**

```bash
# Feature 002 may need to rebase if main has changed
git rebase main  # Or merge main into feature-002 branch
git merge feature-002-[name]
# Resolve any conflicts (should be minimal)
# Run tests, verify Feature 002 integrates cleanly
```

**Step 3: Merge Feature 003**

```bash
git rebase main  # Or merge main into feature-003 branch
git merge feature-003-[name]
# Run tests, verify Feature 003 integrates cleanly
```

**Step 4: End-to-End Testing**

```bash
# Start your application
# Test that all three features work together
# Example: Create a task (Feature 001), set its priority (Feature 002), share with a user (Feature 003)
```

**Document merge conflicts** (if any):
- How many conflicts did you encounter?
- In which files?
- What did they reveal about your decomposition?

A clean merge (0-1 conflicts) is proof your decomposition was excellent.

---

### Phase 5: Clean Up & Prepare for Next Steps

```bash
# Remove worktrees (optional, keep them if you want to preserve history)
git worktree remove ../feature-001-[name]
git worktree remove ../feature-002-[name]
git worktree remove ../feature-003-[name]

# Or keep them and document them in your README
# This shows reviewers your multi-session workflow
```

**Total Execution Time**: 2-3 hours for 3 features built in parallel
(vs 4.5-6 hours if built sequentially)

---

## Section 3: Measurement — Time Tracking & Productivity Analysis (30 minutes)

Now you quantify the value of decomposition thinking. This is not theoretical — it's real data showing concrete productivity gains.

### Time Tracking Worksheet

**Complete this worksheet** (adapted from Lesson 1-4 examples):

| Metric | Sequential Estimate | Parallel Actual | Notes |
|--------|-------|---------|-------|
| **Feature 001** | 60 min | 60 min | Foundation feature, built first |
| **Feature 002** | 50 min | 45 min (parallel) | Built simultaneously with 003 |
| **Feature 003** | 50 min | 45 min (parallel) | Built simultaneously with 002 |
| **Integration** | 30 min | 15 min | Minimal conflicts = good decomposition |
| **Testing** | 30 min | 20 min | End-to-end testing simplified |
| **Documentation** | 20 min | 20 min | (not parallelizable) |
| **TOTAL** | **240 min** | **165 min** | **1.45x speedup** |

**Your numbers will likely be different** — the important part is doing the math correctly.

### Analysis Questions

**1. Speedup Multiplier**

```
Speedup = Sequential Total ÷ Parallel Total
        = 240 min ÷ 165 min
        = 1.45x
```

**Typical range**: 2-3x speedup for well-decomposed systems (Feature 002/003 built simultaneously saves 90-100 minutes)

**If your speedup is < 2x**: Likely cause:
- Merge conflicts (indicates dependencies not as clean as expected)
- Integration testing took longer (hidden integration issues)
- One feature took much longer than others (unbalanced decomposition)

**2. Integration Quality**

Count merge conflicts:
- **0 conflicts**: Excellent decomposition, clear boundaries
- **1-2 conflicts**: Good decomposition, minor overlaps
- **3+ conflicts**: Problematic decomposition, features not sufficiently independent

What did conflicts reveal about your decomposition?

**3. Code Quality vs Speed**

Did parallelization sacrifice code quality?
- Same test pass rate? YES
- Same code review standards? YES
- Fewer bugs introduced? Often YES (parallel work encouraged better specs)

Conclusion: Parallelization **improved** code quality by forcing better upfront decomposition.

---

## Section 4: GitHub Repository & Documentation (30 minutes)

Your capstone is only valuable if you can show it to others. Document your work so employers understand what you learned.

### Repository Structure

Create a clean GitHub repository with this structure:

```
task-management-app/
├── README.md (main documentation)
├── DECOMPOSITION.md (how you broke it down)
├── TIME_TRACKING.md (actual measurements)
├── src/
│   ├── feature-001-crud/
│   │   ├── models.py (task model)
│   │   ├── routes.py (CRUD endpoints)
│   │   └── tests.py
│   ├── feature-002-priorities/
│   │   ├── models.py (priority extensions)
│   │   ├── routes.py (priority endpoints)
│   │   └── tests.py
│   ├── feature-003-sharing/
│   │   ├── models.py (sharing model)
│   │   ├── routes.py (sharing endpoints)
│   │   └── tests.py
│   └── shared/
│       ├── database.py
│       ├── config.py
│       └── utils.py
├── .github/workflows/
│   └── tests.yml (CI/CD proving integration works)
└── docker-compose.yml (optional: run locally)
```

### README.md Template

```markdown
# Task Management App — Decomposition Thinking Case Study

## What We Built

A task management application with three features:
1. **Task CRUD** — Create, read, update, delete tasks
2. **Priority Levels** — Set priorities, filter by priority, sort by deadline
3. **Sharing** — Share tasks with team members, manage permissions

All built in **parallel** using decomposition thinking.

## How We Built It

### Decomposition Approach

We broke the system into 3 independent features with clear integration contracts:

- **Feature 001 (Core)**: Defines the task data model, CRUD endpoints
- **Feature 002 (Enhancement)**: Extends task with priority field, adds filtering
- **Feature 003 (Enhancement)**: Adds sharing model, permission checks

Integration contracts:
- Feature 002 depends on Feature 001's task model (reads task ID, updates task schema)
- Feature 003 depends on Feature 001's task model (reads task ID)
- Features 002 and 003 are **independent** — can be built simultaneously

### Parallel Workflow

We used Git worktrees to enable 3 simultaneous development sessions:

```bash
git worktree add ../feature-001-crud main
git worktree add ../feature-002-priorities main
git worktree add ../feature-003-sharing main

# Ran /sp.specify, /sp.plan, /sp.tasks, /sp.implement in each worktree simultaneously
```

## Results

| Metric | Sequential Estimate | Parallel Actual | Speedup |
|--------|-------|---------|---------|
| Total Time | 240 min | 165 min | **1.45x** |
| Merge Conflicts | — | 0 | Excellent decomposition |
| Code Quality | — | Same | No quality sacrifice |

### Key Insight

Sequential approach: "I can code fast" (60 min per feature)
Parallel approach: "I can coordinate teams" (all 3 features simultaneously)

The bottleneck isn't coding speed — it's coordination. With clear specs and decomposition thinking, 1 person can coordinate 3 independent AI agents (or junior developers) as efficiently as they code alone.

## What Worked Well

1. **Clear specs eliminated merge conflicts** — Developers (or agents) knew exact boundaries, minimal rework
2. **Independent features enabled true parallelization** — No blocking, no context switching between features
3. **Shared data model** — All features use same task model, ensuring consistency

## What We'd Do Differently

If rebuilding this system:
1. Feature 003 (Sharing) might depend on roles/permissions model — would add a Feature 004
2. Feature 002 could have more sophisticated sorting (deadline, priority, custom) — might warrant decomposition

But for a capstone project, this system perfectly demonstrates decomposition thinking.

## Transferability

**How does this apply beyond AI agents?**

This same decomposition thinking enables:
- **Junior developers**: Clear specs → they work independently → minimal merge conflicts
- **Distributed teams**: Time zones don't matter → specs are documentation → asynchronous work
- **Product teams**: Stakeholders don't attend daily syncs → specs are communication → decisions async
- **Large organizations**: 100-person teams decompose same way → specs eliminate meetings

The pattern scales from 1 person + 3 agents to 1 person + 10-15 agents to 10 people + 50-person org.

## How to Run

```bash
# Install dependencies
pip install -r requirements.txt

# Run tests
pytest

# Start the server
python main.py

# Server available at http://localhost:8000
```

## Next Steps

- Deploy to production (Chapters 10-11 cover deployment)
- Add analytics (track which features users prefer)
- Scale to 5-7 features following same decomposition pattern
- Apply SpecKit orchestration patterns from Lesson 7
```

### TIME_TRACKING.md Template

```markdown
# Time Tracking Worksheet

## Baseline: Sequential Approach

If we built features one after another:

| Feature | Estimated Time | Reason |
|---------|--------|---------|
| Feature 001 (Task CRUD) | 60 min | Core model, setup, basic tests |
| Feature 002 (Priorities) | 50 min | Extend model, add endpoints, tests |
| Feature 003 (Sharing) | 50 min | New model, permission checks, tests |
| Integration & Testing | 30 min | Merge, conflict resolution, end-to-end tests |
| Documentation | 20 min | README, code comments, examples |
| **TOTAL SEQUENTIAL** | **210 min** | |

## Actual: Parallel Approach

With parallel workflows:

| Phase | Actual Time | Notes |
|-------|--------|---------|
| Specification (all 3 in parallel) | 20 min | Saved 40 min vs 60 min sequential (3 × 20 min) |
| Planning & Tasks (all 3 in parallel) | 25 min | Saved 55 min vs 75 min sequential (3 × 25 min) |
| Implementation (all 3 in parallel) | 65 min | Longest feature determined time (not sum of all 3) |
| Integration & Merging | 15 min | Clean merges due to good decomposition |
| Testing | 20 min | End-to-end validation |
| Documentation | 20 min | Not parallelizable |
| **TOTAL PARALLEL** | **165 min** | |

## Speedup Analysis

```
Sequential Total: 210 minutes
Parallel Total:   165 minutes
Speedup Multiplier: 210 ÷ 165 = 1.27x

Time Saved: 45 minutes
Percentage Saved: 45 ÷ 210 = 21.4%
```

## What Drove the Speedup

1. **Feature 002 built while Feature 001 was finishing** (saved ~50 min)
2. **Feature 003 built while Feature 001 was finishing** (saved ~50 min)
3. **Parallel planning and tasks generation** (saved ~40 min)
4. **But**: Integration and testing still sequential (15-20 min)
5. **Documentation never parallelizable** (20 min)

So actual savings: 50 + 50 + 40 - 20 (extra integration time) = 120 minutes potential
But we only saved 45 minutes. Why?

**Likely reasons**:
- Implementation times overlapped but weren't perfectly simultaneous
- Some integration complexity emerged during implementation
- Documentation took longer than expected

**Still a 1.27x speedup** on a 3-feature system. At 5-7 features, speedup typically hits 2-3x.

## Merge Conflicts Report

| Branch | Conflicts | Lines | Resolution Time |
|--------|-----------|-------|-----------------|
| feature-001 merge | 0 | — | 2 min (fast-forward) |
| feature-002 merge | 0 | — | 2 min (fast-forward) |
| feature-003 merge | 1 | sharing.py:42 | 5 min (resolved manually) |
| **TOTAL** | **1** | **1 conflict** | **9 min** |

**Interpretation**: 1 conflict across 3 features is excellent. Indicates features were well-decomposed with minimal overlap.

## Conclusions

1. **Decomposition thinking delivered measurable speedup** (1.27x on 3 features, likely 2-3x on 5 features)
2. **Clean decomposition = fewer merge conflicts = faster integration**
3. **Time was not spent on conflict resolution** — spent on meaningful work
4. **Code quality maintained** — parallelization did not introduce bugs or technical debt

**Key insight**: This is not about coding faster. This is about orchestration efficiency. Good decomposition eliminates coordination overhead.
```

---

## Section 5: Reflection & Narrative (30 minutes)

Now you reflect on what you learned and craft the narrative that will convince employers this matters.

### Reflection Questions

**Part 1: Decomposition Insights** (10 minutes)

Write 2-3 paragraphs answering these questions:

1. **What made your features parallelizable?**
   - What design decisions enabled Feature 002 and Feature 003 to be built simultaneously?
   - What if you had designed them differently? Would they still be parallelizable?

2. **What would have happened with poor decomposition?**
   - Imagine if Features 001, 002, and 003 all modified the same `task.py` file
   - Or if Feature 003 required changes to Feature 002's priority logic
   - How would that have affected your speedup?

3. **Aha moment: When did decomposition click for you?**
   - Was it during specification? Planning? Implementation? Merging?
   - What specific moment made you understand: "This is why specs matter"?

**Example reflection** (what good looks like):

> "The key to parallelization was realizing Feature 002 and 003 only needed Feature 001's task data model — they didn't need Feature 001 to be *complete*, just stable. I defined the task model clearly in Feature 001's spec, and Feature 002/003 could build against that contract immediately, without waiting for Feature 001's implementation. If I'd tangled Feature 002's priority logic with Feature 001's core model (like storing priority as a string instead of an enum), Feature 002 and 003 would have had hidden dependencies and couldn't be built in parallel. The decomposition insight is: clear contracts, independent implementations."

---

### Portfolio Narrative: Your 2-Minute Pitch

This is how you'll explain your project to an interviewer or hiring manager. It should:
- Emphasize **strategic thinking**, not tool proficiency
- Show **transferability** to human teams
- Demonstrate **concrete value** (speedup, quality, scalability)
- Position you as a **creative orchestrator**

#### What NOT to Say

❌ "I used git worktrees to run 3 Claude Code sessions in parallel"
❌ "I learned how to manage multiple terminals simultaneously"
❌ "I used SpecKit Plus to write specs faster"

These are **tool descriptions**, not strategic insights. Employers don't hire for tool proficiency; they hire for thinking.

#### What TO Say

✅ "I demonstrated decomposition thinking — the ability to break complex systems into parallelizable units with clear integration contracts. I designed a task management system with 3 independent features, built them in parallel, and delivered a 1.4x speedup with zero quality sacrifice. More importantly, I learned that merge conflicts don't happen from bad code — they happen from bad decomposition. Good specs eliminate coordination overhead entirely. This pattern scales from coordinating 3 AI agents to coordinating 15-person teams."

### Your Portfolio Narrative (Structured)

**Opening** (1 sentence, hook):
> "I built a [Task Management / Blog / API Wrapper] application using decomposition thinking — a pattern that enables 1 person to coordinate 10-15 autonomous agents (or teams) with zero coordination overhead."

**Design** (2-3 sentences, show strategic thinking):
> "The critical insight was that the 3 features didn't need to be sequential — they had clear dependencies (Feature 001 core, Features 002-003 independent). I designed specs that captured these contracts explicitly, so each feature could be developed autonomously without stepping on the others' toes."

**Execution** (2-3 sentences, show results):
> "We built all 3 features in parallel using git worktrees and the SpecKit Plus workflow. Implementation time: 65 minutes (all 3 simultaneously) vs 180 minutes sequential. Total project: 165 minutes parallel vs 240 minutes sequential = 1.4x speedup. But the real achievement: 0 merge conflicts, same test coverage, zero quality sacrifice."

**Strategic Insight** (2-3 sentences, show transferability):
> "This isn't about being a faster coder — it's about orchestrating teams. The same decomposition thinking that coordinates 3 AI agents can coordinate 10-15 human developers or distributed teams. Good decomposition eliminates sync meetings, reduces project coordination overhead, and lets teams move asynchronously. Specs become the communication protocol; developers become autonomous orchestrators."

**Closing** (1 sentence, your identity):
> "I'm a creative orchestrator. I can decompose complex systems, design clear contracts, and coordinate autonomous teams at scale."

**Practice saying this out loud** (2 minutes). Record yourself. Listen back. Refine.

---

## Section 6: Portfolio Narrative — GitHub as Proof (20 minutes)

Your GitHub repository IS your portfolio artifact. Make it shine.

### What Employers Look For

When an employer reviews your capstone project:

1. **Repository structure**: Is the code organized? (YES)
2. **Commit history**: Does the history show parallel work? (Check branch structure)
3. **README quality**: Do I understand what you built and why? (Comprehensive README)
4. **Integration quality**: Did you actually achieve parallelization or just claim it? (0-1 merge conflicts = proof)
5. **Time tracking**: Can you prove the speedup or is it theoretical? (Actual measurements in worksheet)
6. **Reflection**: Do you understand what you built, or did you just follow instructions? (Deep reflection essay)

### GitHub "Proof Points"

Make these visible in your repository:

**1. Proof of Parallel Work: Branch Structure**

```bash
git log --graph --oneline --all

# Should look like:
# *   Merge pull request #3: feature-003-sharing
# |\
# | * [60 commits] feature-003-sharing work
# * | Merge pull request #2: feature-002-priorities
# |/|
# | * [50 commits] feature-002-priorities work
# * | Merge pull request #1: feature-001-crud
# |/
# * [40 commits] feature-001-crud work
# * Initial commit (main)
```

This graph proves you built 3 features in parallel.

**2. Proof of Integration Quality: Zero Conflicts**

In your README:

> "Merge Conflicts: 0 across all 3 features. This indicates excellent decomposition — features had clear boundaries and didn't step on each other's toes."

**3. Proof of Speedup: TIME_TRACKING.md**

Include actual measurements showing parallel speedup vs sequential estimate.

**4. Proof of Understanding: DECOMPOSITION.md**

Document your decomposition decisions:

```markdown
# Decomposition Design

## Feature 001: Task CRUD
- **Responsibility**: Core task data model, CRUD endpoints
- **Provides**: Task API, user authentication
- **Depends on**: Nothing (foundational feature)

## Feature 002: Priorities
- **Responsibility**: Priority levels, sorting, filtering
- **Provides**: Priority filter API
- **Depends on**: Feature 001's task model
- **Integration Contract**: Feature 001 exports `Task` model with `id` field; Feature 002 adds `priority` field to task schema

## Feature 003: Sharing
- **Responsibility**: Sharing tasks, permissions
- **Provides**: Sharing API
- **Depends on**: Feature 001's task model
- **Integration Contract**: Feature 001 exports `Task` model with `id` field; Feature 003 creates `SharedTask` references

## Parallelization Analysis

Features 002 and 003 can be built simultaneously because:
1. Both depend only on Feature 001 (core model)
2. Neither modifies Feature 001's core implementation
3. Neither depends on Feature 002 or 003's implementation
4. Clear contracts prevent hidden dependencies

If we had designed Features 002 and 003 to share a "preferences" table:
- They would conflict on the schema
- Could not be built in parallel
- Would require coordination meetings

Clear separation of concerns enabled parallelization.
```

---

## Section 7: Capstone Submission Checklist

Before you consider your capstone complete, verify you have all required artifacts:

### Code Repository
- [ ] GitHub repository created with clean structure
- [ ] All 3 feature branches merged into main
- [ ] All tests passing on main branch
- [ ] No merge conflicts (or documented conflicts with learnings)
- [ ] Code follows consistent style and conventions

### Documentation
- [ ] README.md (overview, features, how to run)
- [ ] DECOMPOSITION.md (feature design, integration contracts)
- [ ] TIME_TRACKING.md (actual measurements, speedup analysis)
- [ ] Commit messages show parallel work (branches, timestamps)
- [ ] .github/workflows/tests.yml (CI/CD proving integration)

### Reflection & Narrative
- [ ] Reflection essay (1-2 pages, addressing decomposition insights)
- [ ] Portfolio narrative (2-minute pitch, transferability focus)
- [ ] LEARNING.md (what you learned about decomposition, scaling)

### Demonstration (Optional but Recommended)
- [ ] README includes "How to Run" section with copy-paste commands
- [ ] Server/app starts successfully locally
- [ ] End-to-end walkthrough (create task, set priority, share) works
- [ ] Tests pass

### Portfolio Submission Format

When sharing with potential employers:

**Email / Portfolio Site**:
> "I built a task management application demonstrating decomposition thinking — the ability to coordinate autonomous teams at scale. The GitHub repository shows parallel development, measurable speedup, and integration quality. The reflection essay demonstrates strategic understanding of how this pattern applies to team coordination."
>
> [GitHub repository link]

**Interview Talking Points**:
1. System overview (what you built)
2. Decomposition design (why features are independent)
3. Parallel execution (how you achieved speedup)
4. Measurement proof (actual time saved)
5. Strategic insight (transferability to human teams)
6. Scale reflection (what changes at 10-15 features?)

---

## Section 8: Capstone Evaluation Rubric

Use this rubric to assess your own work (or help others understand what "excellent" looks like):

### Decomposition Quality (1-5 scale)

**5 — Excellent**: Features are truly independent, clear contracts, minimal/no merge conflicts, could easily extend to 5-7 features following same pattern

**4 — Good**: Features are mostly independent, clear contracts, 1-2 minor merge conflicts, ready to demonstrate to employers

**3 — Acceptable**: Features have some overlap, contracts mostly clear, 2-3 merge conflicts requiring resolution, demonstrates understanding but not mastery

**2 — Needs Work**: Features have hidden dependencies, contracts unclear, frequent merge conflicts, indicates decomposition thinking not yet internalized

**1 — Incomplete**: Features are tangled, no clear contracts, impossible to build in parallel, decomposition not attempted

**Your Score**: _____ (Aim for 4-5 to be portfolio-worthy)

---

### Execution Quality (1-5 scale)

**5 — Excellent**: All 3 features working, comprehensive tests (unit + integration), code is clean and follows conventions, deployment ready (or documented why not deploying)

**4 — Good**: All 3 features working, good test coverage, code is clean, some minor issues, needs minor polish for production

**3 — Acceptable**: All 3 features implemented, basic tests, code works but could be cleaner, several minor bugs/issues fixed during integration

**2 — Needs Work**: Features mostly working, incomplete tests, code has issues, multiple bugs discovered during integration

**1 — Incomplete**: Features not fully working, minimal testing, code has critical issues

**Your Score**: _____ (Aim for 4-5)

---

### Measurement Quality (1-5 scale)

**5 — Excellent**: Detailed time tracking (all phases), speedup calculation correct, honest analysis of results, identified what drove speedup

**4 — Good**: Time tracking for major phases, speedup calculated correctly, basic analysis of results

**3 — Acceptable**: Time tracking documented, speedup calculation attempted, minimal analysis

**2 — Needs Work**: Time tracking incomplete, speedup calculation not accurate, little analysis

**1 — Incomplete**: No time tracking, no speedup measurement

**Your Score**: _____ (Aim for 4-5)

---

### Reflection Quality (1-5 scale)

**5 — Excellent**: Deep insights into decomposition, clear connection to transferability, identifies what worked/didn't, proposes improvements for next iteration

**4 — Good**: Clear insights into decomposition, addresses transferability, acknowledges strengths and areas for improvement

**3 — Acceptable**: Basic reflection on decomposition, mentions transferability, surface-level insights

**2 — Needs Work**: Minimal reflection, doesn't address transferability, generic observations

**1 — Incomplete**: No reflection or essay

**Your Score**: _____ (Aim for 4-5)

---

### Portfolio Narrativeness (1-5 scale)

**5 — Excellent**: Compelling story, emphasizes strategic thinking over tools, would impress employers, demonstrates mastery

**4 — Good**: Clear story, strategic thinking evident, professional presentation, would be well-received

**3 — Acceptable**: Story is there, mixes tools and strategy, adequate for portfolio, needs polish

**2 — Needs Work**: Focuses on tools, minimal strategic thinking, needs significant revisions

**1 — Incomplete**: No portfolio narrative

**Your Score**: _____ (Aim for 4-5)

---

### Overall Capstone Score

Add up your 5 scores and divide by 5.

- **4.5-5.0**: Portfolio-ready. Confidently present this project to employers.
- **4.0-4.5**: Strong capstone. Could use minor polish, but demonstrates mastery.
- **3.5-4.0**: Solid work. Demonstrates understanding, minor gaps in excellence.
- **3.0-3.5**: Acceptable. Demonstrates core learning, but not yet portfolio-ready.
- Below 3.0: Needs significant revision. Consider rebuilding with focus on weaker areas.

---

## Section 9: From 3 Features to 10-15 Agents — Scaling Reflection

You just built a 3-feature system using decomposition thinking. What would change if you needed to scale to 10-15 features?

### What Stays the Same

- **Core principle**: Good decomposition eliminates coordination overhead
- **Workflow**: Specs → Plans → Tasks → Implement → Integration
- **Measurement**: Time tracking validates speedup
- **Quality**: Good decomposition improves code quality

### What Changes at 5-7 Features

| Aspect | 3 Features | 5-7 Features |
|--------|---|---|
| Specification time | 20 min | 40-50 min (specs interact more) |
| Merge conflicts | 0-1 | 2-4 (expected, manageable) |
| Integration testing | 20 min | 45-60 min (more combinations) |
| Coordination overhead | None (3 agents) | Moderate (need clear contracts) |
| Manual terminal management | Manageable | Gets tedious (contracts help, L6) |

### What Changes at 10-15 Features

| Aspect | 5-7 Features | 10-15 Features |
|---|---|---|
| Specification time | 40-50 min | 90-120 min (specs must be precise) |
| Merge conflicts | 2-4 | 8-15 (expected, need strategies) |
| Integration testing | 45-60 min | 2-3 hours (combinatorial explosion) |
| Coordination overhead | Moderate | High (manual coordination impossible) |
| Solution | Contract-based coordination (L6) | SpecKit orchestration (L7) |
| Human role | Terminal manager | Creative director (specs + review) |

### 10-15 Agent Reality Check

**Q: Can 1 person really coordinate 15 AI agents?**

A: Yes, with excellent decomposition. The key insight:
- Decomposition quality determines if 15 agents can work independently
- **Poor decomposition at 15 agents**: Agents constantly conflict, blocks, waiting for dependencies. Fails.
- **Excellent decomposition at 15 agents**: Agents work autonomously. Human reviews specs (upstream), merges code (downstream). Scales.

**The bottleneck is ALWAYS decomposition**, not tools or agents.

### Application to Human Teams

This insight applies directly to human team scaling:
- **3 junior developers**: Can be managed manually with daily standups
- **10-15 junior developers**: Need specs and async communication (daily standups become bottleneck)
- **50-person organization**: Needs decomposition thinking across teams, projects, product areas

Your capstone project is proof you understand organizational scaling at the 10-15 agent level. This is valuable to CTOs and VPs Engineering.

---

## Final Reflection & Celebration (20 minutes)

### Your Capstone Celebration

You've just completed something significant. Pause and recognize it.

**What you accomplished**:
- ✓ Designed a 3-feature system from first principles
- ✓ Executed full SpecKit Plus workflow with parallel work
- ✓ Integrated 3 independent implementations cleanly
- ✓ Measured actual productivity gains
- ✓ Created a portfolio-worthy GitHub project
- ✓ Articulated your learning in a professional narrative
- ✓ Demonstrated mastery of decomposition thinking

**What this means**:
- You are not a faster coder (though you might be)
- You are a **creative orchestrator**
- You can coordinate teams at scale
- You understand how specs eliminate meetings and reduce coordination overhead
- You've proven decomposition thinking works in practice

**Who you are now**:
> "I am a developer who can break complex problems into parallelizable units, coordinate autonomous agents (or teams), and deliver multi-feature systems efficiently. I understand decomposition thinking as a strategic capability, not just a coding technique. I can explain my work to non-technical stakeholders and transfer this pattern to human team coordination."

### Journaling: Your Takeaway

Spend 5-10 minutes journaling:

1. **Biggest insight**: What's the most important thing you learned about decomposition?
2. **Aha moment**: When did it click? What made you understand this pattern?
3. **Transferability**: How does this apply beyond AI agents? What parallels exist in human teams?
4. **Confidence**: How confident are you now in coordinating 5 agents? 10? 15?
5. **Next step**: If you were to build a 5-feature system next, what would you do differently?

---

### Try With AI: Portfolio Refinement & Retrospective Insights

You've completed your capstone project. Now use AI as your editorial partner to refine your portfolio narrative and gain retrospective insights.

**Tool**: Claude Code CLI or your AI companion (you've mastered this interface across 32 chapters)

**Prompt Set** (3 progressive prompts):

**Prompt 1: Portfolio Narrative Feedback**

```
Review my capstone project portfolio narrative. I want to ensure it emphasizes decomposition thinking and strategic capability, not tool proficiency. Here's my pitch:

[PASTE YOUR 2-MINUTE NARRATIVE FROM SECTION 6]

Does this narrative:
1. Emphasize strategic thinking over tools?
2. Demonstrate transferability to human teams?
3. Show concrete value (speedup, quality, scale)?
4. Position me as a creative orchestrator?

Give me specific feedback on what works and what to strengthen.
```

**Expected Outcome**: AI feedback identifying where your narrative emphasizes tools vs strategy. Refine it to focus on orchestration capability. Typical feedback: "Your speedup metrics are great, but add a sentence about how this scales to human team coordination."

---

**Prompt 2: Retrospective Analysis**

```
I just completed a 3-feature capstone project using decomposition thinking. I measured:
- Sequential estimate: 240 minutes
- Parallel actual: 165 minutes
- Speedup: 1.45x
- Merge conflicts: [YOUR NUMBER]

Analyze what this tells me about my decomposition quality. What would change if I:
1. Built 5 features instead of 3?
2. Built 10-15 features?
3. Hired junior developers instead of using AI agents?

What insights does my data reveal about scaling coordination?
```

**Expected Outcome**: AI analysis of your specific numbers. Typical insights: "Your 1.45x speedup suggests well-designed specs but some integration overlap. At 5 features, you'd likely see 2-2.5x speedup if you tighten Feature 002/003 boundary contracts. At 10-15 features, decomposition quality becomes critical — loose specs would cause exponential merge conflicts."

---

**Prompt 3: Strategic Capability Reflection**

```
I've completed Lessons 1-9 of Chapter 32 and built a capstone project. I can now:
- Coordinate 3 agents/developers in parallel
- Achieve 1.4-2x productivity speedup through decomposition
- Design systems with clear integration contracts
- Understand why specs eliminate coordination overhead

If I wanted to scale this capability to coordinating 10-15 agents, what are the critical gaps in my understanding? What would I learn in Lesson 7 (SpecKit orchestration) that I'm missing? How would contract-based coordination differ from my manual worktree approach?
```

**Expected Outcome**: AI reflection on your readiness for enterprise-scale coordination. Typical insights: "Your manual coordination works for 3 features. At 10-15, you need explicit integration contracts (Lesson 6) to prevent coordination overhead, and SpecKit orchestration (Lesson 7) where Claude itself coordinates parallel sessions. But these patterns only work if decomposition is excellent."

---

**Safety & Ethics Note**:

AI gives you feedback and analysis, but YOU are responsible for:
- Verifying your time tracking measurements are honest
- Ensuring your portfolio narrative is authentic (no exaggeration)
- Acknowledging what you learned vs what you found challenging
- Being transparent about decomposition quality (if you had 10 merge conflicts, that's valuable learning too)

Employers value honesty about challenges more than perfection.

---

## Closing: You Are Ready

You've completed Chapter 32: *The Super AI Orchestra - Managing 10-15 AI Agents*.

Over eight lessons, you learned:
1. **Lesson 1**: How to set up parallel specifications using git worktrees
2. **Lesson 2**: How to scale parallelization to planning and task generation
3. **Lesson 3**: How to execute parallel implementation and integrate cleanly
4. **Lesson 4**: How sandboxing enables safe multi-session work
5. **Lesson 5**: How decomposition patterns scale from 3 to 5-7 features (FIRST CLIMAX)
6. **Lesson 6**: How explicit integration contracts enable autonomous coordination
7. **Lesson 7**: How SpecKit orchestration coordinates 5-10 agents (SECOND CLIMAX)
8. **Lesson 8** (This capstone): How to prove mastery with a real project

**You learned the pattern that enables creative orchestration at scale.**

Not because you're a faster coder. But because you understand how **clear specs eliminate coordination overhead**, **good decomposition enables autonomous work**, and **excellent decomposition scales to 10-15 agents or human teams**.

This is the skill CTOs look for. This is how startups scale. This is how you move from "I can code" to "I can build and lead teams."


You are now a **creative orchestrator**. Go build something at scale.

---

**Generated by lesson-writer v3.0.0**
Source: specs/002-chapter-32-redesign/spec.md
Created: 2025-11-06
Workflow: /sp.implement
